Functionality

1. Upload a downloaded video from your device
2. Run the emotion classifier on the video to derive an emotion dataframe with the timestamp as index and the emotion predicted at that moment (interval of 10 seconds) 
3. Extract the audio of the downloaded video and play it when the button 'Start Practising' is pressed
4. Match the timestamp from the audio and check if the emotion predicted is equal to the emotion in the dataframe from the downloaded video 
5. Calculate score on the basis of how many matches are there 